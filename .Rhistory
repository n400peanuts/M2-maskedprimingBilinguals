neuralNet(inputs=c(1,1), weights1=matrix(c(1,1,1,1), nrow=2), weights2=matrix(c(1,1,1,1), nrow=2), bias=c(5,.5), nOut=2, nHiddenLayers=1, nHiddenUnits=2, type='sigmoid')
neuralNet <- function(inputs, weights1, weights2=NULL, bias1, bias2=NULL, nOut=1, nHiddenLayers=0, nHiddenUnits=0, type='perceptron')
{
out <- vector(length=nOut, mode="numeric");#build the output vector
#build the necessary hidden layer unit vector, if there's such a layer
if (nHiddenLayers==1)
hidden <- vector(length=nHiddenUnits)
else
if (nHiddenLayers!=0) stop('This neuralNet can only manage up to 1 layer of hidden units (that is, nHiddenLayers can only be 0 or 1');
#check the neuron type
if (type!='perceptron' & type!='sigmoid') stop('This neural network can only feature either perceptrons or sigmoid neurons');
#a few checks in dimensionality
if ( length(inputs)!=nrow(weights1) ) stop('Input length and nrow(weights1) should be the same');
if ( nHiddenLayers==0 & ncol(weights1)!=nOut ) stop('ncol(weights1) and nOut should be the same length');
if ( nHiddenLayers==1 & ncol(weights1)!=nHiddenUnits ) stop('ncol(weights1) and nHiddenUnits should be the same length');
#if ( exists('weights2') )
#  {
#  if ( nHiddenLayers==1 & nrow(weights2)!=nHiddenUnits ) stop('nrow(weights2) and nHiddenUnits should be the same length');
#  if ( nHiddenLayers==1 & ncol(weights2)!=nOut ) stop('ncol(weights2) and nOut should be the same length');
#  };
if (type=='perceptron')
if (nHiddenLayers==0)
out <- ifelse( inputs %*% weights1 + bias1 > 0, 1, 0)
else
{
hidden <- ifelse( inputs %*% weights1 + bias1 > 0, 1, 0);
out <- ifelse( hidden %*% weights2 + bias2 > 0, 1, 0);
}
else
if (nHiddenLayers==0)
out <- 1/ (1+ exp(-(inputs %*% weights1 + bias1)))
else
{
hidden <- 1/ (1+ exp(-(inputs %*% weights1 + bias1)));
out <- 1/ (1+ exp(-(hidden %*% weights2 + bias2)));
};
return(out);
};
neuralNet(inputs=c(1,100), weights1=matrix(c(1,1,.1,.1), nrow=2), bias1=c(0,0), nOut=2, nHiddenLayers=0, nHiddenUnits=0, type='sigmoid')
neuralNet(inputs=c(1,100), weights1=matrix(c(1,1,.1,.1), nrow=2), bias1=c(0,0), nOut=2, nHiddenLayers=0, nHiddenUnits=0, type='perceptron')
neuralNet(inputs=c(1,100), weights1=matrix(c(1,1,.1,.1), nrow=2), bias1=c(-100,0), nOut=2, nHiddenLayers=0, nHiddenUnits=0, type='perceptron')
neuralNet(inputs=c(1,100), weights1=matrix(c(1,1,.1,.1), nrow=2), bias1=c(-1000,0), nOut=2, nHiddenLayers=0, nHiddenUnits=0, type='perceptron')
neuralNet(inputs=c(1,1), weights1=matrix(c(1,1,1,1), nrow=2), weights2=matrix(c(1,1,1,1), nrow=2), bias1=c(5,.5), bias2=c(0,0), nOut=2, nHiddenLayers=1, nHiddenUnits=2, type='sigmoid')
neuralNet(inputs=c(1,1), weights1=matrix(c(1,1,1,1), nrow=2), weights2=matrix(c(1,1,1,1), nrow=2), bias1=c(5,.5), bias2=c(100,0), nOut=2, nHiddenLayers=1, nHiddenUnits=2, type='sigmoid')
neuralNet(inputs=c(1,1), weights1=matrix(c(1,1,1,1), nrow=2), weights2=matrix(c(1,1,1,1), nrow=2), bias1=c(5,.5), bias2=c(100,10), nOut=2, nHiddenLayers=1, nHiddenUnits=2, type='sigmoid')
neuralNet(inputs=1:10, weights1=matrix(rep(1,100), nrow=10), weights2=matrix(c(1,1,1,1), nrow=2), bias1=c(5,.5), bias2=c(100,10), nOut=2, nHiddenLayers=1, nHiddenUnits=2, type='sigmoid')
1:10
matrix(rep(1,100), nrow=10)
neuralNet(inputs=1:10, weights1=matrix(rep(1,100), nrow=10), weights2=matrix(rep(1,100), nrow=10), bias1=rep(1,10), bias2=rep(1,10), nOut=10, nHiddenLayers=1, nHiddenUnits=10, type='sigmoid')
neuralNet(inputs=1:10, weights1=matrix(rep(1,100), nrow=10), weights2=matrix(rep(1,100), nrow=10), bias1=rep(-1,10), bias2=rep(1,10), nOut=10, nHiddenLayers=1, nHiddenUnits=10, type='sigmoid')
neuralNet(inputs=1:10, weights1=matrix(rep(1,100), nrow=10), weights2=matrix(rep(1,100), nrow=10), bias1=rep(-1,10), bias2=rep(-1,10), nOut=10, nHiddenLayers=1, nHiddenUnits=10, type='sigmoid')
neuralNet(inputs=1:10, weights1=matrix(rep(1,100), nrow=10), weights2=matrix(rep(1,100), nrow=10), bias1=rep(-1,10), bias2=rep(-10,10), nOut=10, nHiddenLayers=1, nHiddenUnits=10, type='sigmoid')
neuralNet(inputs=1:10, weights1=matrix(rep(1,100), nrow=10), weights2=matrix(rep(1,100), nrow=10), bias1=rep(-10,10), bias2=rep(-10,10), nOut=10, nHiddenLayers=1, nHiddenUnits=10, type='sigmoid')
neuralNet(inputs=1:10, weights1=matrix(rep(1,100), nrow=10), weights2=matrix(rep(1,100), nrow=10), bias1=rep(-100,10), bias2=rep(-10,10), nOut=10, nHiddenLayers=1, nHiddenUnits=10, type='sigmoid')
neuralNet(inputs=1:10, weights1=matrix(rep(1,100), nrow=10), weights2=matrix(rep(1,100), nrow=10), bias1=rep(-100,10), bias2=rep(-100,10), nOut=10, nHiddenLayers=1, nHiddenUnits=10, type='sigmoid')
neuralNet(inputs=1:10, weights1=matrix(rep(1,100), nrow=10), weights2=matrix(rep(1,100), nrow=10), bias1=rep(-100,10), bias2=rep(-100,10), nOut=10, nHiddenLayers=1, nHiddenUnits=10, type='perceptron')
neuralNet(inputs=1:10, weights1=matrix(rep(1,100), nrow=10), weights2=matrix(rep(1,100), nrow=10), bias1=rep(-100,10), bias2=rep(1,10), nOut=10, nHiddenLayers=1, nHiddenUnits=10, type='perceptron')
.61*74
.61*140
2759.2+1410.70
localGitDir <- '~/Google Drive File Stream/My Drive/research/misc/m2-maskedMorphPrimingBilinguals/git/M2-maskedprimingBilinguals/';
setwd(localGitDir);
read.table(paste(localGitDir, '/preprocessedData.txt', sep = ''), header = T, sep='\t', dec='.') -> masterFile;
#------------------------------#
#### outliers trimming, ita ####
#------------------------------#
subset(masterFile, language=="ita") -> masterFileIta;
dataItaAcc <- subset(masterFileIta$accuracy==1);
dataIta <- subset(dataItaAcc, masterFileIta$rt>280 & masterFileIta$rt<2500 & masterFileIta$subject!=15 & masterFileIta$subject!=2 & masterFileIta$subject!=31 & masterFileIta$target!= "guano" & masterFileIta$target!= "uggia" & masterFileIta$target!= "vello" & masterFileIta$lexicality=="word");
dataItaAcc <- subset(masterFileIta, accuracy==1);
dataIta <- subset(dataItaAcc, masterFileIta$rt>280 & masterFileIta$rt<2500 & masterFileIta$subject!=15 & masterFileIta$subject!=2 & masterFileIta$subject!=31 & masterFileIta$target!= "guano" & masterFileIta$target!= "uggia" & masterFileIta$target!= "vello" & masterFileIta$lexicality=="word");
nrow(dataItaAcc)-nrow(dataIta);
dataItaAcc <- subset(masterFileIta, lexicality=="word" & accuracy==1);
dataIta <- subset(dataItaAcc, masterFileIta$rt>280 & masterFileIta$rt<2500 & masterFileIta$subject!=15 & masterFileIta$subject!=2 & masterFileIta$subject!=31 & masterFileIta$target!= "guano" & masterFileIta$target!= "uggia" & masterFileIta$target!= "vello");
nrow(dataItaAcc)-nrow(dataIta);
dataItaAcc <- subset(masterFileIta, lexicality=="word" & accuracy==1);
dataIta <- subset(dataItaAcc, masterFileIta$rt>280 & masterFileIta$rt<2500 & masterFileIta$subject!=15 & masterFileIta$subject!=2 & masterFileIta$subject!=31 & masterFileIta$target!= "guano" & masterFileIta$target!= "uggia" & masterFileIta$target!= "vello");
dataItaAcc <- subset(masterFileIta, lexicality=="word" & accuracy==1);
dataItaAcc <- subset(masterFileIta, lexicality=="word" & accuracy==1);
dataIta <- subset(dataItaAcc, rt>280 & rt<2500 & subject!=15 & subject!=2 & subject!=31 & target!= "guano" & target!= "uggia" & target!= "vello");
nrow(dataItaAcc)-nrow(dataIta);
((nrow(dataItaAcc)-nrow(dataIta)) / nrow(dataItaAcc);
(nrow(dataItaAcc)-nrow(dataIta)) / nrow(dataItaAcc);
nrow(dataItaAcc)-nrow(dataIta);
#------------------------------#
#### outliers trimming, eng ####
#------------------------------#
subset(masterFile, language=="eng")-> masterFileEng;
dataEngAcc <- subset(masterFileEng, lexicality=="word" & accuracy==1);
dataEngAcc <- subset(masterFileEng, lexicality=="word" & accuracy==1);
dataEng <- subset(masterFileEng, rt>300 & rt<2000 & subject!=15 & subject!=22 & subject!=43);
nrow(dataEngAcc)-nrow(dataEng);
(nrow(dataEngAcc)-nrow(dataEng)) / nrow(dataEngAcc);
dataEng <- subset(dataEngAcc, rt>300 & rt<2000 & subject!=15 & subject!=22 & subject!=43);
nrow(dataEngAcc)-nrow(dataEng);
(nrow(dataEngAcc)-nrow(dataEng)) / nrow(dataEngAcc);
nrow(dataEng);
library(lmerTest);
dataIta$morphType <- relevel(dataIta$morphType, "or");
contrasts(dataIta$relatedness);
contrasts(dataIta$morphType);
italmer0 <- lmer(-1000/rt ~ 1 + (1|subject) + (1|target), data= dataIta, REML = F);
italmer1 <- lmer(-1000/rt ~ trialCount + rotation + (1|subject) + (1|target), data= dataIta, REML = F);
anova(italmer0, italmer1);
italmer1 <- lmer(-1000/rt ~ freqTarget + lengthTarget + nTarget + (1|subject) + (1|target), data= dataIta, REML = F);
anova(italmer0, italmer1); #strong improvement in GoF
anova(italmer1);
italmer2 <- lmer(-1000/rt ~ relatedness * morphType + freqTarget + (1|subject) + (1|target), data= dataIta, REML = T);
summary(italmer2);
italmer2b <- lmer(-1000/rt ~ relatedness * morphType + freqTarget + (1|subject) + (1|target), data=subset(dataIta, abs(scale(resid(italmer2)))<2.5), REML = T);
anova(italmer2b);
summary(italmer2b);
dataIta$morphType <- relevel(dataIta$morphType, "op");
italmer2c <- lmer(-1000/rt ~ relatedness * morphType + freqTarget + (1|subject) + (1|target), data=dataIta, REML = T);
italmer2d <- lmer(-1000/rt ~ relatedness * morphType + freqTarget + (1|subject) + (1|target), data=subset(dataIta, abs(scale(resid(italmer2c)))<2.5), REML = T);
summary(italmer2d);
dataEng$morphType <- relevel(dataEng$morphType, "or");
contrasts(dataEng$relatedness);
contrasts(dataEng$morphType);
englmer0 <- lmer(-1000/rt ~ 1 + (1|subject) + (1|target), data= dataEng, REML = F);
englmer1 <- lmer(-1000/rt ~ trialCount + rotation + (1|subject) + (1|target), data= dataEng, REML = F);
anova(englmer0, englmer1);
englmer1 <- lmer(-1000/rt ~ freqTarget + lengthTarget + nTarget + (1|subject) + (1|target), data= dataEng, REML = F);
anova(englmer0, englmer1); #strong improvement in GoF
anova(englmer1);
englmer2 <- lmer(-1000/rt ~ relatedness * morphType + freqTarget + lengthTarget + (1|subject) + (1|target), data= dataEng, REML = T);
summary(englmer2);
englmer2b <- lmer(-1000/rt ~ relatedness * morphType + freqTarget + lengthTarget + (1|subject) + (1|target), data=subset(dataEng, abs(scale(resid(englmer2)))<2.5), REML = T);
anova(englmer2b);
summary(englmer2b); #here we get the parameters for contrasts across individual conditions
dataEng$morphType <- relevel(dataEng$morphType, "op");
englmer2c <- lmer(-1000/rt ~ relatedness * morphType + freqTarget + lengthTarget + (1|subject) + (1|target), data=dataEng, REML = T);
englmer2d <- lmer(-1000/rt ~ relatedness * morphType + freqTarget + lengthTarget + (1|subject) + (1|target), data=subset(dataEng, abs(scale(resid(englmer2c)))<2.5), REML = T);
summary(englmer2d);
summary(englmer2b); #here we get the parameters for contrasts across individual conditions
summary(englmer2d); #here we get the contrast between transparent and opaque pairs
summary(englmer2b); #here we get the parameters for contrasts across individual conditions
rbind(dataEng, dataIta) -> crossExp;
summary(crossExp);
crosslmer <- lmer(-1000/rt ~ relatedness * morphType * language + freqTarget + lengthTarget + (1|subject) + (1|target), data = crossExp, REML = T);
crosslmerb <- lmer(-1000/rt ~ relatedness * morphType * language + freqTarget + lengthTarget + (1|subject) + (1|target), data = subset(crossExp, abs(scale(resid(crosslmer)))<2.5), REML = T);
anova(crosslmerb);
pptFeatures <- unique(dataEng[,c('subject','age','gender','handedness','rotation','phonemicFluency', 'phonemicComprehension','morphComprehension','spelling','readingComprehension','vocabulary','oralComprehension','aoa1', 'aoa2', 'aoa3','aoa4','aoa5','aoa6')]);
summary(pptFeatures);
round(cor(pptFeatures[,c(6:12)], use='pairwise.complete.obs'), digits=2);
temp <- as.vector(round(cor(pptFeatures[,c(6:12)], use='pairwise.complete.obs'), digits=2));
fivenum(temp[temp!=1]);
par(mfrow=c(2,4));
par(mar=c(5,5,4,.5)+.1);
par(lwd=2);
hist(phonemicFluency, breaks = seq(0,50,5), main = '(a) Phon Fluency', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,50), cex.axis=2, las=1);
hist(phonemicComprehension, breaks = seq(0,13,1), main = '(b) Phon Comprehension', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,50), cex.axis=2, las=1);
hist(morphComprehension, breaks = seq(0,10,1), main = '(c) Morph Awareness', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,50), cex.axis=2, las=1);
hist(spelling, breaks = seq(0,20,2), main = '(d) Spelling', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,50), cex.axis=2, las=1);
hist(readingComprehension, breaks = seq(0,7,1), main = '(e) Read Comprehension', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,50), cex.axis=2, las=1);
hist(vocabulary, breaks = seq(0,20,2), main = '(f) Vocabulary', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,50), cex.axis=2, las=1);
hist(oralComprehension, breaks = seq(0,6,1), main = '(g) Oral comprehension', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,50), cex.axis=2, las=1);
hist(overallProf, breaks = seq(-2.5,2,.5), main = '(h) Overall Proficiency', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,50), cex.axis=2, las=1);
par(mfrow=c(1,1));
attach(pptFeatures);
par(mfrow=c(2,4));
par(mar=c(5,5,4,.5)+.1);
par(lwd=2);
hist(phonemicFluency, breaks = seq(0,50,5), main = '(a) Phon Fluency', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,50), cex.axis=2, las=1);
hist(phonemicComprehension, breaks = seq(0,13,1), main = '(b) Phon Comprehension', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,50), cex.axis=2, las=1);
hist(morphComprehension, breaks = seq(0,10,1), main = '(c) Morph Awareness', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,50), cex.axis=2, las=1);
hist(spelling, breaks = seq(0,20,2), main = '(d) Spelling', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,50), cex.axis=2, las=1);
hist(readingComprehension, breaks = seq(0,7,1), main = '(e) Read Comprehension', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,50), cex.axis=2, las=1);
hist(vocabulary, breaks = seq(0,20,2), main = '(f) Vocabulary', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,50), cex.axis=2, las=1);
hist(oralComprehension, breaks = seq(0,6,1), main = '(g) Oral comprehension', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,50), cex.axis=2, las=1);
hist(overallProf, breaks = seq(-2.5,2,.5), main = '(h) Overall Proficiency', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,50), cex.axis=2, las=1);
par(mfrow=c(1,1));
detach(pptFeatures);
fivenum(temp[temp!=1]);
proficiencylmer0 <- lmer(-1000/rt ~ relatedness * morphType + freqTarget + lengthTarget + (1|subject) + (1|target), data = dataEng, REML=F);
proficiencylmer1 <- lmer(-1000/rt ~ relatedness * morphType * phonemicFluency + freqTarget + lengthTarget + (1|subject) + (1|target), data = dataEng, REML=F);
anova(proficiencylmer0, proficiencylmer1);
proficiencylmer1b <- lmer(-1000/rt ~ relatedness * morphType * phonemicFluency + trialCount + freqTarget + lengthTarget + (1|subject) + (1|target), data = subset(dataEng, abs(scale(resid(proficiencylmer1)))<2.5), REML=T);
anova(proficiencylmer1b);
summary(proficiencylmer1b);
pippo <- data.frame(effect('relatedness:morphType:phonemicFluency', proficiencylmer1b, se=list(level=.95), xlevels=4));
pippo[,c('fit','lower','upper')] <- inv(pippo[,c('fit','lower','upper')]);
ggplot(data = pippo, aes(x=relatedness, y=fit)) +
#geom_line() +
geom_point() +
geom_errorbar(aes(ymin=lower, ymax=upper), width=.2) +
facet_grid(morphType ~ phonemicFluency)
library(ggplot2);
pippo <- data.frame(effect('relatedness:morphType:phonemicFluency', proficiencylmer1b, se=list(level=.95), xlevels=4));
pippo[,c('fit','lower','upper')] <- inv(pippo[,c('fit','lower','upper')]);
ggplot(data = pippo, aes(x=relatedness, y=fit)) +
#geom_line() +
geom_point() +
geom_errorbar(aes(ymin=lower, ymax=upper), width=.2) +
facet_grid(morphType ~ phonemicFluency)
#---------------------------#
#### estimated RTs/plots ####
#---------------------------#
inv <- function(x) {-1000/x};
pippo <- data.frame(effect('relatedness:morphType:phonemicFluency', proficiencylmer1b, se=list(level=.95), xlevels=4));
library(effects);
pippo <- data.frame(effect('relatedness:morphType:phonemicFluency', proficiencylmer1b, se=list(level=.95), xlevels=4));
pippo[,c('fit','lower','upper')] <- inv(pippo[,c('fit','lower','upper')]);
ggplot(data = pippo, aes(x=relatedness, y=fit)) +
#geom_line() +
geom_point() +
geom_errorbar(aes(ymin=lower, ymax=upper), width=.2) +
facet_grid(morphType ~ phonemicFluency)
dataEng$morphType <- relevel(dataEng$morphType, "tr");
proficiencylmer1b <- lmer(-1000/rt ~ relatedness * morphType * phonemicFluency + freqTarget + lengthTarget + (1|subject) + (1|target), data = subset(dataEng, abs(scale(resid(proficiencylmer1)))<2.5), REML=T);
summary(proficiencylmer1b);
proficiencylmer2 <- lmer(-1000/rt ~ relatedness *  morphType * phonemicComprehension + freqTarget + lengthTarget + (1|subject) + (1|target), data = dataEng, REML=F);
anova(proficiencylmer0, proficiencylmer2);
proficiencylmer3 <- lmer(-1000/rt ~ relatedness *  morphType * morphComprehension + freqTarget + lengthTarget + (1|subject) + (1|target), data = dataEng, REML=F);
anova(proficiencylmer0,proficiencylmer3);
proficiencylmer4 <- lmer(-1000/rt ~ relatedness * morphType * spelling + freqTarget + lengthTarget + (1|subject) + (1|target), data = dataEng, REML=F);
anova(proficiencylmer0, proficiencylmer4);
proficiencylmer5 <- lmer(-1000/rt ~ relatedness * morphType * readingComprehension + freqTarget + lengthTarget + (1|subject) + (1|target), data = dataEng, REML=F);
anova(proficiencylmer0, proficiencylmer5);
proficiencylmer6 <- lmer(-1000/rt ~ relatedness * morphType * vocabulary + freqTarget + lengthTarget + (1|subject) + (1|target), data = dataEng, REML=F);
anova(proficiencylmer0,proficiencylmer6);
proficiencylmer7 <- lmer(-1000/rt ~ relatedness * morphType * oralComprehension + freqTarget + lengthTarget + (1|subject) + (1|target), data = dataEng, REML=F);
anova(proficiencylmer0,proficiencylmer7);
anova(proficiencylmer0, proficiencylmer1);
anova(proficiencylmer0, proficiencylmer2);
anova(proficiencylmer0,proficiencylmer3);
anova(proficiencylmer0, proficiencylmer4);
anova(proficiencylmer0, proficiencylmer5);
anova(proficiencylmer0,proficiencylmer6);
anova(proficiencylmer0,proficiencylmer7);
proficiencylmer1b <- lmer(-1000/rt ~ relatedness * morphType * phonemicFluency + trialCount + freqTarget + lengthTarget + (1|subject) + (1|target), data = subset(dataEng, abs(scale(resid(proficiencylmer1)))<2.5), REML=T);
anova(proficiencylmer1b);
proficiencylmer2b <- lmer(-1000/rt ~ relatedness *  morphType * phonemicComprehension + freqTarget + lengthTarget + (1|subject) + (1|target), data = subset(dataEng, abs(scale(resid(proficiencylmer2)))<2.5), REML=F);
anova(proficiencylmer2b);
proficiencylmer3b <- lmer(-1000/rt ~ relatedness *  morphType * morphComprehension + freqTarget + lengthTarget + (1|subject) + (1|target), data = subset(dataEng, abs(scale(resid(proficiencylmer3)))<2.5), REML=F);
anova(proficiencylmer3b);
proficiencylmer4b <- lmer(-1000/rt ~ relatedness * morphType * spelling + freqTarget + lengthTarget + (1|subject) + (1|target), data = subset(dataEng, abs(scale(resid(proficiencylmer4)))<2.5), REML=F);
anova(proficiencylmer4b);
proficiencylmer5b <- lmer(-1000/rt ~ relatedness * morphType * readingComprehension + trialCount + freqTarget + lengthTarget + (1|subject) + (1|target), data = subset(dataEng, abs(scale(resid(proficiencylmer5)))<2.5), REML=F);
anova(proficiencylmer5b);
proficiencylmer6b <- lmer(-1000/rt ~ relatedness * morphType * vocabulary + trialCount + freqTarget + lengthTarget + (1|subject) + (1|target), data = subset(dataEng, abs(scale(resid(proficiencylmer6)))<2.5), REML=F);
anova(proficiencylmer6b);
proficiencylmer7b <- lmer(-1000/rt ~ relatedness * morphType * oralComprehension + freqTarget + lengthTarget + (1|subject) + (1|target), data = subset(dataEng, abs(scale(resid(proficiencylmer7)))<2.5), REML=F);
anova(proficiencylmer7b);
pippo <- data.frame(effect('relatedness:morphType:phonemicFluency', proficiencylmer1b, se=list(level=.95), xlevels=4));
pippo[,c('fit','lower','upper')] <- inv(pippo[,c('fit','lower','upper')]);
ggplot(data = pippo, aes(x=relatedness, y=fit)) +
#geom_line() +
geom_point() +
geom_errorbar(aes(ymin=lower, ymax=upper), width=.2) +
facet_grid(morphType ~ phonemicFluency)
pippo <- data.frame(effect('relatedness:morphType:morphComprehension', proficiencylmer3b, se=list(level=.95), xlevels=3));
pippo[,c('fit','lower','upper')] <- inv(pippo[,c('fit','lower','upper')]);
ggplot(data = pippo, aes(x=relatedness, y=fit)) +
#geom_line() +
geom_point() +
geom_errorbar(aes(ymin=lower, ymax=upper), width=.2) +
facet_grid(morphType ~ morphComprehension)
pippo <- data.frame(effect('relatedness:morphType:phonemicFluency', proficiencylmer1b, se=list(level=.95), xlevels=3));
pippo[,c('fit','lower','upper')] <- inv(pippo[,c('fit','lower','upper')]);
ggplot(data = pippo, aes(x=relatedness, y=fit)) +
#geom_line() +
geom_point() +
geom_errorbar(aes(ymin=lower, ymax=upper), width=.2) +
facet_grid(morphType ~ phonemicFluency)
pippo <- data.frame(effect('relatedness:morphType:morphComprehension', proficiencylmer3b, se=list(level=.95), xlevels=4));
pippo[,c('fit','lower','upper')] <- inv(pippo[,c('fit','lower','upper')]);
ggplot(data = pippo, aes(x=relatedness, y=fit)) +
#geom_line() +
geom_point() +
geom_errorbar(aes(ymin=lower, ymax=upper), width=.2) +
facet_grid(morphType ~ morphComprehension)
pippo <- data.frame(effect('relatedness:morphType:spelling', proficiencylmer4b, se=list(level=.95), xlevels=4));
pippo[,c('fit','lower','upper')] <- inv(pippo[,c('fit','lower','upper')]);
ggplot(data = pippo, aes(x=relatedness, y=fit)) +
#geom_line() +
geom_point() +
geom_errorbar(aes(ymin=lower, ymax=upper), width=.2) +
facet_grid(morphType ~ spelling)
temp <- data.frame(effect('relatedness:morphType:phonemicFluency', proficiencylmer1b, se=list(level=.95), xlevels=4));
temp[,c('fit','lower','upper')] <- inv(temp[,c('fit','lower','upper')]);
ggplot(data = temp, aes(x=relatedness, y=fit)) +
#geom_line() +
geom_point() +
geom_errorbar(aes(ymin=lower, ymax=upper), width=.2) +
facet_grid(morphType ~ phonemicFluency)
#although only phonemic fluency is frankly significant, we want to check whether the two variables coming close behind shows the same effect, at least qualitatively:
temp <- data.frame(effect('relatedness:morphType:morphComprehension', proficiencylmer3b, se=list(level=.95), xlevels=4));
temp[,c('fit','lower','upper')] <- inv(temp[,c('fit','lower','upper')]);
ggplot(data = temp, aes(x=relatedness, y=fit)) +
#geom_line() +
geom_point() +
geom_errorbar(aes(ymin=lower, ymax=upper), width=.2) +
facet_grid(morphType ~ morphComprehension)
temp <- data.frame(effect('relatedness:morphType:spelling', proficiencylmer4b, se=list(level=.95), xlevels=4));
temp[,c('fit','lower','upper')] <- inv(temp[,c('fit','lower','upper')]);
ggplot(data = temp, aes(x=relatedness, y=fit)) +
#geom_line() +
geom_point() +
geom_errorbar(aes(ymin=lower, ymax=upper), width=.2) +
facet_grid(morphType ~ spelling)
dataEng$morphType <- relevel(dataEng$morphType, "tr");
proficiencylmer1b <- lmer(-1000/rt ~ relatedness * morphType * phonemicFluency + freqTarget + lengthTarget + (1|subject) + (1|target), data = subset(dataEng, abs(scale(resid(proficiencylmer1)))<2.5), REML=T);
summary(proficiencylmer1b);
temp <- data.frame(effect('relatedness:morphType:phonemicFluency', proficiencylmer1b, se=list(level=.95), xlevels=4));
temp[,c('fit','lower','upper')] <- inv(temp[,c('fit','lower','upper')]);
ggplot(data = temp, aes(x=relatedness, y=fit)) +
#geom_line() +
geom_point() +
geom_errorbar(aes(ymin=lower, ymax=upper), width=.2) +
facet_grid(morphType ~ phonemicFluency);
summary(proficiencylmer1b);
anova(proficiencylmer1b);
anova(proficiencylmer2b);
anova(proficiencylmer3b);
anova(proficiencylmer4b);
anova(proficiencylmer5b);
anova(proficiencylmer6b);
anova(proficiencylmer7b);
head(pptFeatures)
summary(pptFeatures);
#-----------#
#### aoa ####
#-----------#
head(pptFeatures);
par(mar=c(5,5,4,.5)+.1);
par(lwd=2);
attach(pptFeatures);
hist(aoa1, breaks = seq(0,15,1), main = '(a) Age first exposed', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,50), cex.axis=2, las=1);
hist(aoa1, breaks = seq(0,15,1), main = '(a) Age first exposed', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,30), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,50), cex.axis=2, las=1);
hist(aoa1, breaks = seq(0,15,1), main = '(a) Age first exposed', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,30), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,30), cex.axis=2, las=1);
hist(aoa2, breaks = seq(1,5,1), main = '(b) Daily use', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,50), cex.axis=2, las=1);
hist(aoa2, breaks = seq(.5,5.5,1), main = '(b) Daily use', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,50), cex.axis=2, las=1);
barplot(aoa2, breaks = seq(.5,5.5,1), main = '(b) Daily use', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,50), cex.axis=2, las=1);
hist(aoa2, breaks = seq(.5,5.5,1), main = '(b) Daily use', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,50), cex.axis=2, las=1);
hist(aoa2, breaks = seq(.5,5.5,1), main = '(b) Daily use', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,30), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,30), cex.axis=2, las=1);
barplot(aoa, breaks = seq(0,10,1), main = '(c) Where did you learn?', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,50), cex.axis=2, las=1);
barplot(aoa3, main = '(c) Where did you learn?', cex.main=2,  ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
aoa3
hist(aoa3, main = '(c) Where did you learn?', cex.main=2,  ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
barplot(table(aoa3), main = '(c) Where did you learn?', cex.main=2,  ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,50), cex.axis=2, las=1);
barplot(table(aoa3), main = '(c) Where did you learn?', cex.main=2,  ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(2, at=c(0,50), cex.axis=2, las=1);
barplot(table(aoa3), main = '(c) Where did you learn?', cex.main=2,  ylab = 'N of participants', ylim=c(0,65), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(2, at=c(0,65), cex.axis=2, las=1);
barplot(table(aoa3), main = '(c) Where did you learn?', cex.main=2,  ylab = 'N of participants', ylim=c(0,65), cex.names=2, axes=F, col=grey(.80), border=grey(0));
axis(2, at=c(0,65), cex.axis=2, las=1);
barplot(table(aoa3), main = '(c) Where did you learn?', cex.main=2,  ylab = 'N of participants', ylim=c(0,65), cex.lab=2, cex.names=2, axes=F, col=grey(.80), border=grey(0));
axis(2, at=c(0,65), cex.axis=2, las=1);
pptFeatures$aoa4
recode(pptFeatures$aoa, 1='yes');
pptFeatures$aoa7 <- 'yes';
head(pptFeatures)
pptFeatures$aoa7[pptFeatures$aoa4==2] <- 'no';
summary(pptFeatures)
pptFeatures$aoa7 <- factor(pptFeatures$aoa7)
summary(pptFeatures)
(18+(60*2))/78
pptFeatures$aoa4 <- NULL
summary(pptFeatures)
names(pptFeatures)
names(pptFeatures)[18]
names(pptFeatures)[18] <- 'aoa4'
names(pptFeatures)[18]
summary(pptFeatures)
hist(table(aoa4), main = '(d) Multilingual context', cex.main=2, ylab = 'N of participants', ylim=c(0,65), cex.lab=2, cex.names=2, axes=F, col=grey(.80), border=grey(0));
axis(2, at=c(0,65), cex.axis=2, las=1);
barplot(table(aoa4), main = '(d) Multilingual context', cex.main=2, ylab = 'N of participants', ylim=c(0,65), cex.lab=2, cex.names=2, axes=F, col=grey(.80), border=grey(0));
axis(2, at=c(0,65), cex.axis=2, las=1);
detach(pptFeatures)
attach(pptFeatures)
barplot(table(aoa4), main = '(d) Multilingual context', cex.main=2, ylab = 'N of participants', ylim=c(0,65), cex.lab=2, cex.names=2, axes=F, col=grey(.80), border=grey(0));
axis(2, at=c(0,65), cex.axis=2, las=1);
hist(aoa5, breaks = seq(0,7,1), main = '(e) Self rated proficiency', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,50), cex.axis=2, las=1);
hist(aoa5, breaks = seq(0,5,1), main = '(e) Self rated proficiency', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,50), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,50), cex.axis=2, las=1);
hist(aoa5, breaks = seq(0,5,1), main = '(e) Self rated proficiency', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,30), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,30), cex.axis=2, las=1);
barplot(table(aoa6), main = '(f) Additional languages?', cex.main=2, ylab = 'N of participants', ylim=c(0,65), cex.lab=2, cex.names=2, axes=F, col=grey(.80), border=grey(0));
axis(2, at=c(0,65), cex.axis=2, las=1);
getwd()
par(mfrow=c(2,3));
par(mar=c(5,5,4,.5)+.1);
par(lwd=2);
attach(pptFeatures);
hist(aoa1, breaks = seq(0,15,1), main = '(a) Age first exposed', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,30), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,30), cex.axis=2, las=1);
hist(aoa2, breaks = seq(.5,5.5,1), main = '(b) Daily use', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,30), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,30), cex.axis=2, las=1);
barplot(table(aoa3), main = '(c) Where did you learn?', cex.main=2,  ylab = 'N of participants', ylim=c(0,65), cex.lab=2, cex.names=2, axes=F, col=grey(.80), border=grey(0));
axis(2, at=c(0,65), cex.axis=2, las=1);
barplot(table(aoa4), main = '(d) Multilingual context', cex.main=2, ylab = 'N of participants', ylim=c(0,65), cex.lab=2, cex.names=2, axes=F, col=grey(.80), border=grey(0));
axis(2, at=c(0,65), cex.axis=2, las=1);
hist(aoa5, breaks = seq(0,5,1), main = '(e) Self rated proficiency', cex.main=2, xlab = 'Scores', ylab = 'N of participants', ylim=c(0,30), cex.lab=2, axes=F, col=grey(.80), border=grey(0));
axis(1, cex.axis=2);
axis(2, at=c(0,30), cex.axis=2, las=1);
barplot(table(aoa6), main = '(f) Additional languages?', cex.main=2, ylab = 'N of participants', ylim=c(0,65), cex.lab=2, cex.names=2, axes=F, col=grey(.80), border=grey(0));
axis(2, at=c(0,65), cex.axis=2, las=1);
detach(pptFeatures);
par(mfrow=c(1,1));
aoalmer1 <- lmer(-1000/rt ~ relatedness*morphType*aoa1 + freqTarget + lengthTarget + (1|subject) + (1|target), data = dataEng);
anova(proficiencylmer0, aoalmer1);
aoalmer2 <- lmer(-1000/rt ~ relatedness*morphType*aoa2 + freqTarget + lengthTarget + (1|subject) + (1|target), data = dataEng);
anova(proficiencylmer0, aoalmer2);
aoalmer3 <- lmer(-1000/rt ~ relatedness*morphType*aoa3 + freqTarget + lengthTarget + (1|subject) + (1|target), data = dataEng);
anova(proficiencylmer0, aoalmer3);
aoalmer4 <- lmer(-1000/rt ~ relatedness*morphType*aoa4 + freqTarget + lengthTarget + (1|subject) + (1|target), data = dataEng);
anova(proficiencylmer0, aoalmer4);
aoalmer5 <- lmer(-1000/rt ~ relatedness*morphType*aoa5 + freqTarget + lengthTarget + (1|subject) + (1|target), data = dataEng);
anova(proficiencylmer0, aoalmer5);
aoalmer6 <- lmer(-1000/rt ~ relatedness*morphType*aoa6 + freqTarget + lengthTarget + (1|subject) + (1|target), data = dataEng);
anova(proficiencylmer0, aoalmer6);
names(pptFeatures)
#correlation between the individual scores, and between aoa and proficiency
round(cor(pptFeatures[,c(13:18)], use='pairwise.complete.obs'), digits=2, method='spearman');
#correlation between the individual scores, and between aoa and proficiency
round(cor(pptFeatures[,c(13,14,17)], use='pairwise.complete.obs'), digits=2, method='spearman');
summary(pptFeatures)
#correlation between the individual scores, and between aoa and proficiency
round(cor(pptFeatures[,c(13,14,16)], use='pairwise.complete.obs'), digits=2, method='spearman');
#correlation between the individual scores, and between aoa and proficiency
round(cor(pptFeatures[,c(13,14,16)], use='pairwise.complete.obs', method='spearman'), digits=2);
temp <- as.vector(round(cor(pptFeatures[,c(6:12, 13,14,16)], use='pairwise.complete.obs'), digits=2));
round(cor(pptFeatures[,c(6:12, 13,14,16)], use='pairwise.complete.obs', method='spearman'), digits=2);
#correlation between the individual scores, and between aoa and proficiency
round(cor(pptFeatures[,c(13,14,16)], use='pairwise.complete.obs', method='spearman'), digits=2); #aoa2 and aoa5
round(cor(pptFeatures[,c(6:12, 13,14,16)], use='pairwise.complete.obs', method='spearman'), digits=2);
aoalmer1b <- lmer(-1000/rt ~ relatedness*morphType*aoa1 + freqTarget + lengthTarget + (1|subject) + (1|target), data = subset(dataEng, abs(scale(resid(aoaLmer1)))<2.5));
anova(aoalmer1b);
#priming modulation
aoalmer1b <- lmer(-1000/rt ~ relatedness*morphType*aoa1 + freqTarget + lengthTarget + (1|subject) + (1|target), data = subset(dataEng, abs(scale(resid(aoalmer1)))<2.5));
anova(aoalmer1b);
aoalmer2b <- lmer(-1000/rt ~ relatedness*morphType*aoa2 + freqTarget + lengthTarget + (1|subject) + (1|target), data = subset(dataEng, abs(scale(resid(aoalmer2)))<2.5));
anova(aoalmer2b);
aoalmer5b <- lmer(-1000/rt ~ relatedness*morphType*aoa5 + freqTarget + lengthTarget + (1|subject) + (1|target), data = subset(dataEng, abs(scale(resid(aoalmer5)))<2.5));
anova(aoalmer5b);
temp <- data.frame(effect('relatedness:morphType:aoa5', aoalmer5b, se=list(level=.95), xlevels=4));
temp[,c('fit','lower','upper')] <- inv(temp[,c('fit','lower','upper')]);
ggplot(data = temp, aes(x=relatedness, y=fit)) +
#geom_line() +
geom_point() +
geom_errorbar(aes(ymin=lower, ymax=upper), width=.2) +
facet_grid(morphType ~ aoa5);
summary(aoalmer1)
head(dataEng)
dataEng$morphType <- relevel(dataEng$morphType, 'or');
aoalmer5 <- lmer(-1000/rt ~ relatedness*morphType*aoa5 + freqTarget + lengthTarget + (1|subject) + (1|target), data = dataEng);
aoalmer5b <- lmer(-1000/rt ~ relatedness*morphType*aoa5 + freqTarget + lengthTarget + (1|subject) + (1|target), data = subset(dataEng, abs(scale(resid(aoalmer5)))<2.5));
summary(aoalmer5b);
dataEng$morphType <- relevel(dataEng$morphType, 'tr');
aoalmer5 <- lmer(-1000/rt ~ relatedness*morphType*aoa5 + freqTarget + lengthTarget + (1|subject) + (1|target), data = dataEng);
aoalmer5b <- lmer(-1000/rt ~ relatedness*morphType*aoa5 + freqTarget + lengthTarget + (1|subject) + (1|target), data = subset(dataEng, abs(scale(resid(aoalmer5)))<2.5));
summary(aoalmer5b);
head(dataEng)
